{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Logistic Regression with filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truth-value</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>name</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>politics</th>\n",
       "      <th>count1</th>\n",
       "      <th>count2</th>\n",
       "      <th>count3</th>\n",
       "      <th>count4</th>\n",
       "      <th>count5</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12465.json</td>\n",
       "      <td>true</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>education</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>Wisconsin Assembly speaker</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a an online opinion-piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2342.json</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>candidates-biography</td>\n",
       "      <td>republican-party-texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a press release.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "      <td>ethics</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a Democratic debate in Philadelphia, Pa.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  truth-value                                               text  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "5  12465.json         true  The Chicago Bears have had more starting quart...   \n",
       "6   2342.json  barely-true  Jim Dunnam has not lived in the district he re...   \n",
       "7    153.json    half-true  I'm the only person on this stage who has work...   \n",
       "\n",
       "                                topic                    name  \\\n",
       "0                            abortion            dwayne-bohac   \n",
       "1  energy,history,job-accomplishments          scott-surovell   \n",
       "2                      foreign-policy            barack-obama   \n",
       "3                         health-care            blog-posting   \n",
       "4                        economy,jobs           charlie-crist   \n",
       "5                           education               robin-vos   \n",
       "6                candidates-biography  republican-party-texas   \n",
       "7                              ethics            barack-obama   \n",
       "\n",
       "                          job      state    politics  count1  count2  count3  \\\n",
       "0        State representative      Texas  republican     0.0     1.0     0.0   \n",
       "1              State delegate   Virginia    democrat     0.0     0.0     1.0   \n",
       "2                   President   Illinois    democrat    70.0    71.0   160.0   \n",
       "3                         NaN        NaN        none     7.0    19.0     3.0   \n",
       "4                         NaN    Florida    democrat    15.0     9.0    20.0   \n",
       "5  Wisconsin Assembly speaker  Wisconsin  republican     0.0     3.0     2.0   \n",
       "6                         NaN      Texas  republican     3.0     1.0     1.0   \n",
       "7                   President   Illinois    democrat    70.0    71.0   160.0   \n",
       "\n",
       "   count4  count5                                   context  \n",
       "0     0.0     0.0                                  a mailer  \n",
       "1     1.0     0.0                           a floor speech.  \n",
       "2   163.0     9.0                                    Denver  \n",
       "3     5.0    44.0                            a news release  \n",
       "4    19.0     2.0                       an interview on CNN  \n",
       "5     5.0     1.0                 a an online opinion-piece  \n",
       "6     3.0     1.0                          a press release.  \n",
       "7   163.0     9.0  a Democratic debate in Philadelphia, Pa.  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create df of all the data\n",
    "df_liar = pd.read_csv(\"train.tsv\", encoding=\"utf8\", sep=\"\\t\", names=[\"id\", \"truth-value\", \n",
    "                                                                     \"text\", \"topic\", \"name\", \"job\", \n",
    "                                                                     \"state\", \"politics\", \"count1\", \"count2\", \n",
    "                                                                     \"count3\", \"count4\", \"count5\", \"context\"])\n",
    "\n",
    "df_liar.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in trainset: 110580\n",
      "Number of distinct words in trainset: 11057\n",
      "Number of statements in train dataset 10240\n",
      "['say', 'annies', 'list', 'political', 'group', 'support', 'thirdtrimester', 'abortion', 'demand', 'decline', 'coal', 'start', 'started', 'natural', 'gas', 'took', 'started', 'begin', 'president', 'george', 'w', 'bush', 'administration', 'hillary', 'clinton']\n",
      "['say', 'annies', 'list', 'political', 'group', 'support', 'thirdtrimester', 'abortion', 'demand', 'decline', 'coal', 'start', 'started', 'natural', 'gas', 'took', 'begin', 'president', 'george', 'w', 'bush', 'administration', 'hillary', 'clinton', 'agrees']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "import string\n",
    "\n",
    "countlines = 0 \n",
    "\n",
    "allwords = []\n",
    "with open(\"train.tsv\", encoding=\"utf8\") as tsvfile:    #open training set\n",
    "    lines = csv.reader(tsvfile, delimiter=\"\\t\")        #convert file to lines\n",
    "    for line in lines:\n",
    "        statement = line[2]                     #get statement from each line \n",
    "        lostrings = statement.split(\" \")        #convert string to list of strings\n",
    "        new_lostrings = []\n",
    "        countlines += 1                         #count number of lines so we know the number of statements\n",
    "        for word in lostrings:\n",
    "            word = nltk.WordNetLemmatizer().lemmatize(\n",
    "                word.translate(str.maketrans('', '', string.punctuation)).lower()) # remove punctuation & lemmatize\n",
    "            if word not in stopwords.words('english') and not word.isdigit():\n",
    "                new_lostrings.append(word)\n",
    "        allwords.extend(new_lostrings)\n",
    "\n",
    "vocab = []                          #initialize a list for all the distint words in the trainset\n",
    "for word in allwords:\n",
    "    if word in vocab:               #do not add word if word is already in vocabulary \n",
    "        continue \n",
    "    else:\n",
    "        vocab.append(word)\n",
    "\n",
    "print(\"Number of words in trainset:\", len(allwords))\n",
    "print(\"Number of distinct words in trainset:\", len(vocab))\n",
    "print(\"Number of statements in train dataset\",countlines)\n",
    "print(allwords[:25])\n",
    "print(vocab[:25])    #here we can see that the vocabulary only contains distinct words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 statements: [['say', 'annies', 'list', 'political', 'group', 'support', 'thirdtrimester', 'abortion', 'demand'], ['decline', 'coal', 'start', 'started', 'natural', 'gas', 'took', 'started', 'begin', 'president', 'george', 'w', 'bush', 'administration'], ['hillary', 'clinton', 'agrees', 'john', 'mccain', 'voting', 'give', 'george', 'bush', 'benefit', 'doubt', 'iran']]\n",
      "First 3 labels: ['false', 'half-true', 'mostly-true']\n"
     ]
    }
   ],
   "source": [
    "statements = []\n",
    "labels = []\n",
    "\n",
    "with open(\"train.tsv\", encoding=\"utf8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    for line in tsvreader:\n",
    "        label = line[1]\n",
    "        aline = line[2]\n",
    "        bline = aline.split(\" \")\n",
    "        cline = []\n",
    "        for word in bline:\n",
    "            word = nltk.WordNetLemmatizer().lemmatize(\n",
    "                word.translate(str.maketrans('', '', string.punctuation)).lower()) # remove punctuation & lemmatize\n",
    "            if word not in stopwords.words('english') and not word.isdigit():\n",
    "                cline.append(word)\n",
    "        labels.append(label)\n",
    "        statements.append(cline)\n",
    "\n",
    "print(\"First 3 statements:\", statements[:3]) \n",
    "print(\"First 3 labels:\", labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will remove the statements that are not 'false' or 'true' (to be able to apply binomial logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['say', 'annies', 'list', 'political', 'group', 'support', 'thirdtrimester', 'abortion', 'demand'], ['health', 'care', 'reform', 'legislation', 'likely', 'mandate', 'free', 'sex', 'change', 'surgery'], ['chicago', 'bear', 'starting', 'quarterback', 'last', 'year', 'total', 'number', 'tenured', 'uw', 'faculty', 'fired', 'last', 'two', 'decade']]\n"
     ]
    }
   ],
   "source": [
    "i = -1\n",
    "for label in labels:\n",
    "    i += 1 \n",
    "    if label == \"false\":\n",
    "         continue \n",
    "    if label == \"true\": \n",
    "         continue\n",
    "    else: \n",
    "        del statements[i]\n",
    "        i = i-1 \n",
    "        \n",
    "print(statements[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671\n"
     ]
    }
   ],
   "source": [
    "print(len(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671\n"
     ]
    }
   ],
   "source": [
    "labels = [label for label in labels if label not in (\"barely-true\", \"half-true\", \"mostly-true\", \"pants-fire\")]\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671\n"
     ]
    }
   ],
   "source": [
    "labels = [label for label in labels if label not in (\"barely-true\", \"half-true\", \"mostly-true\", \"pants-fire\")]\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "rows = len(statements)          \n",
    "columns = len(vocab)       #corresponds to the number of distinct words occuring in the train set \n",
    "matrix = np.zeros((rows, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X matrix \n",
    "counts1 = 0 \n",
    "for statement in statements: \n",
    "    counts2 = 0\n",
    "    for word in vocab:\n",
    "        if word in statement:\n",
    "            count = statement.count(word)       #count how often the word occurs in the statement\n",
    "            matrix[counts1, counts2] = count    #puts number of occurences in the entry corresponding to that word\n",
    "        counts2 += 1 \n",
    "    counts1 += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create y matrix\n",
    "#Create y vector which contains the validity labels of the statements in the train dataset \n",
    "labelsdic ={\"false\":0, \"true\":1}\n",
    "\n",
    "size = len(statements)\n",
    "y_vector = [None] * size\n",
    "\n",
    "counter = 0\n",
    "for label in labels:\n",
    "    y_vector[counter] = labelsdic[label]  #convert the label to the corresponding integer\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(matrix, y_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now preprocess the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 test statements: [['building', 'wall', 'usmexico', 'border', 'take', 'literally', 'year'], ['wisconsin', 'pace', 'double', 'number', 'layoff', 'year'], ['say', 'john', 'mccain', 'ha', 'done', 'nothing', 'help', 'vet']]\n",
      "First 3 test labels: ['true', 'false', 'false']\n"
     ]
    }
   ],
   "source": [
    "teststatements = []\n",
    "testlabels = []\n",
    "\n",
    "with open(\"test.tsv\", encoding=\"utf8\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    for line in tsvreader:\n",
    "        testlabel = line[1]\n",
    "        aline = line[2]\n",
    "        bline = aline.split(\" \")\n",
    "        cline = []\n",
    "        for word in bline:\n",
    "            word = nltk.WordNetLemmatizer().lemmatize(\n",
    "                word.translate(str.maketrans('', '', string.punctuation)).lower()) # remove punctuation & lemmatize\n",
    "            if word not in stopwords.words('english') and not word.isdigit():\n",
    "                cline.append(word)\n",
    "        testlabels.append(testlabel)\n",
    "        teststatements.append(cline)\n",
    "\n",
    "print(\"First 3 test statements:\", teststatements[:3]) \n",
    "print(\"First 3 test labels:\", testlabels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['building', 'wall', 'usmexico', 'border', 'take', 'literally', 'year'], ['wisconsin', 'pace', 'double', 'number', 'layoff', 'year'], ['say', 'john', 'mccain', 'ha', 'done', 'nothing', 'help', 'vet']]\n"
     ]
    }
   ],
   "source": [
    "j = -1\n",
    "for testlabel in testlabels:\n",
    "    j += 1 \n",
    "    if testlabel == \"false\":\n",
    "         continue \n",
    "    if testlabel == \"true\": \n",
    "         continue\n",
    "    else: \n",
    "        del teststatements[j]\n",
    "        j = j-1 \n",
    "        \n",
    "print(teststatements[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabels = [testlabel for testlabel in testlabels if testlabel not in (\"barely-true\", \"half-true\", \"mostly-true\", \"pants-fire\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n",
      "457\n"
     ]
    }
   ],
   "source": [
    "print(len(teststatements))\n",
    "print(len(testlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "rows = len(teststatements)          \n",
    "columns = len(vocab)       #corresponds to the number of distinct words occuring in the train set \n",
    "testmatrix = np.zeros((rows, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test X matrix \n",
    "counts1 = 0 \n",
    "for teststatement in teststatements: \n",
    "    counts2 = 0\n",
    "    for word in vocab:\n",
    "        if word in teststatement:\n",
    "            count = teststatement.count(word)       #count how often the word occurs in the statement\n",
    "            testmatrix[counts1, counts2] = count    #puts number of occurences in the entry corresponding to that word\n",
    "        counts2 += 1 \n",
    "    counts1 += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create y matrix\n",
    "#Create y vector which contains the validity labels of the statements in the train dataset \n",
    "labelsdic ={\"false\":0, \"true\":1}\n",
    "\n",
    "size = len(teststatements)\n",
    "testy_vector = [None] * size\n",
    "\n",
    "counter = 0\n",
    "for testlabel in testlabels:\n",
    "    testy_vector[counter] = labelsdic[testlabel]  #convert the label to the corresponding integer\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n"
     ]
    }
   ],
   "source": [
    "print(len(testy_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5842450765864332\n",
      "267\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = logreg.predict(testmatrix)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(testy_vector, y_hat_test))\n",
    "print(accuracy_score(testy_vector, y_hat_test, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612691466083151\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "#results from when filtering was not applied\n",
    "\n",
    "y_hat_test = logreg.predict(testmatrix)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(testy_vector, y_hat_test))\n",
    "print(accuracy_score(testy_vector, y_hat_test, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['say', 'the', 'annies', 'list'], ['this', 'one', 'as', 'well'], ['to', 'begin', 'in', 'president', 'george', 'w', 'bush', 'administration']]\n"
     ]
    }
   ],
   "source": [
    "example \n",
    "\n",
    "exstatements = [['say', 'the', 'annies', 'list' ],\n",
    "                ['this', 'is', 'another', 'test'],\n",
    "                ['this', 'one', 'as', 'well'],\n",
    "                ['political', 'group', 'support', 'thirdtrimester','abortion', 'on', 'demand'], \n",
    "                ['when', 'did', 'the', 'decline', 'of', 'coal', 'start', 'it', 'started', 'when', 'natural', 'gas', 'took', 'off', 'that', 'started'],\n",
    "                ['to', 'begin', 'in', 'president', 'george', 'w', 'bush', 'administration'], \n",
    "                ['hillary', 'clinton', 'agrees', 'with', 'john', 'mccain', 'by', 'voting', 'to', 'give', 'george', 'bush', 'the', 'benefit', 'of', 'the', 'doubt', 'on', 'iran']]\n",
    "exlabels = ['false', 'half-true', 'true','half-true', 'mostly-true', 'true', 'half-true']\n",
    "\n",
    "i = -1\n",
    "for label in exlabels:\n",
    "    i += 1 \n",
    "    if label == \"false\":\n",
    "         continue \n",
    "    if label == \"true\": \n",
    "         continue\n",
    "    else: \n",
    "        del exstatements[i]\n",
    "        i = i - 1 \n",
    "        \n",
    "print(exstatements) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
